{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc8c134b",
   "metadata": {},
   "source": [
    "### B A T C H - C L O N I N G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fa6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('high')\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torch_setup import compile_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e2d41b",
   "metadata": {},
   "source": [
    "### D E V I C E "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf6876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b54487",
   "metadata": {},
   "source": [
    "### E N V - D A T A S E T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae13b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations shape: (1000000, 11)\n",
      "Actions shape: (1000000, 3)\n",
      "Rewards shape: (1000000,)\n",
      "State dim: 11, Action dim: 3, Max action: 0.9999945163726807\n"
     ]
    }
   ],
   "source": [
    "file = 'C:\\OFFLINE RL\\hopper_medium-v2.hdf5'\n",
    "\n",
    "with h5py.File(file, 'r') as f:\n",
    "    \n",
    "    observations = np.array(f['observations'])\n",
    "    actions = np.array(f['actions'])\n",
    "    rewards = np.array(f['rewards'])\n",
    "    \n",
    "print(\"Observations shape:\", observations.shape) \n",
    "print(\"Actions shape:\", actions.shape)            \n",
    "print(\"Rewards shape:\", rewards.shape)\n",
    "\n",
    "state_dim = observations.shape[1]\n",
    "action_dim = actions.shape[1]\n",
    "max_action = np.abs(actions).max()\n",
    "\n",
    "print(f\"State dim: {state_dim}, Action dim: {action_dim}, Max action: {max_action}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d170c",
   "metadata": {},
   "source": [
    "### P R E P A R E - D A T A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394cf6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_tensor = torch.from_numpy(observations).float().to(device)\n",
    "act_tensor = torch.from_numpy(actions).float().to(device)\n",
    "\n",
    "class HOPPER_DATASET(Dataset):\n",
    "    \n",
    "    def __init__(self, observations, actions):\n",
    "\n",
    "        self.observations = observations\n",
    "        self.actions = actions\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.observations)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.observations[index], self.actions[index]\n",
    "    \n",
    "# create dataset\n",
    "\n",
    "dataset = HOPPER_DATASET(obs_tensor, act_tensor)\n",
    "Data_loader = DataLoader(dataset, batch_size = 256, shuffle = True, drop_last = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6192dad",
   "metadata": {},
   "source": [
    "### A S S E M B L Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6f3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_1 = 128\n",
    "head_2 = 256\n",
    "head_3 = 256\n",
    "head_4 = 256\n",
    "\n",
    "hidden_size = 128\n",
    "hidden_size_2 = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828eb9d7",
   "metadata": {},
   "source": [
    "### F E A T U R E "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865be6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Extractor(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden_size = hidden_size, hidden_size_2 = hidden_size_2):\n",
    "        super(Feature_Extractor, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.cal = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(input_dim, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size_2),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            \n",
    "            nn.LayerNorm(hidden_size_2),\n",
    "            nn.Linear(hidden_size_2, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            \n",
    "            nn.Linear(hidden_size, output_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.cal(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6817c20",
   "metadata": {},
   "source": [
    "### P O L I C Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce71661",
   "metadata": {},
   "outputs": [],
   "source": [
    "class policy_net(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_dim = state_dim, action_dim = action_dim, head_1 = head_1, head_2 = head_2, head_3 = head_3, head_4 = head_4, max_action = max_action):\n",
    "        super(policy_net, self).__init__()\n",
    "        \n",
    "        # max action\n",
    "        \n",
    "        self.max_action = max_action\n",
    "        \n",
    "        # feature\n",
    "        \n",
    "        self.feature = Feature_Extractor(state_dim, head_1)\n",
    "        \n",
    "        # norm\n",
    "        \n",
    "        self.norm = nn.LayerNorm(head_1)\n",
    "        \n",
    "        # pos feature\n",
    "        \n",
    "        self.pos_feature = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(head_1, head_2),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            \n",
    "            nn.Linear(head_2, head_3),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            \n",
    "            nn.Linear(head_3, head_4),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        # mu and log std \n",
    "        \n",
    "        self.mu = nn.Linear(head_4, action_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, state):\n",
    "        \n",
    "        # feature\n",
    "        \n",
    "        feature = self.feature(state)\n",
    "        \n",
    "        # norm\n",
    "        \n",
    "        norm = self.norm(feature)\n",
    "        \n",
    "        # pos feature\n",
    "        \n",
    "        pos = self.pos_feature(norm)\n",
    "        \n",
    "        # mu and log std\n",
    "        \n",
    "        mu = self.mu(pos)\n",
    "        action = torch.tanh(mu) * self.max_action\n",
    "        \n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca794d",
   "metadata": {},
   "source": [
    "### S E T U P "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d03afb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_net(\n",
      "  (feature): Feature_Extractor(\n",
      "    (cal): Sequential(\n",
      "      (0): Linear(in_features=11, out_features=128, bias=True)\n",
      "      (1): SiLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): SiLU()\n",
      "      (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (5): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (6): SiLU()\n",
      "      (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (8): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (9): SiLU()\n",
      "      (10): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (11): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (pos_feature): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): SiLU()\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): SiLU()\n",
      "  )\n",
      "  (mu): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# actor net\n",
    "\n",
    "ACTOR_NETWORK = policy_net().to(device)\n",
    "print(ACTOR_NETWORK)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78691867",
   "metadata": {},
   "source": [
    "### O P T I M I Z E R - S C H E D U L E R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3527ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "T_max = 30\n",
    "\n",
    "OPTIMIZER = optim.AdamW(ACTOR_NETWORK.parameters(), lr, weight_decay = 0.001)\n",
    "SCHEDULER = optim.lr_scheduler.CosineAnnealingLR(OPTIMIZER, T_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd031486",
   "metadata": {},
   "source": [
    "### T R A I N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14a68be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.091180\n",
      "Epoch 2/30, Loss: 0.067434\n",
      "Epoch 3/30, Loss: 0.062793\n",
      "Epoch 4/30, Loss: 0.060402\n",
      "Epoch 5/30, Loss: 0.058840\n",
      "Epoch 6/30, Loss: 0.057648\n",
      "Epoch 7/30, Loss: 0.056782\n",
      "Epoch 8/30, Loss: 0.056107\n",
      "Epoch 9/30, Loss: 0.055370\n",
      "Epoch 10/30, Loss: 0.054927\n",
      "Epoch 11/30, Loss: 0.054458\n",
      "Epoch 12/30, Loss: 0.054038\n",
      "Epoch 13/30, Loss: 0.053556\n",
      "Epoch 14/30, Loss: 0.053216\n",
      "Epoch 15/30, Loss: 0.052839\n",
      "Epoch 16/30, Loss: 0.052515\n",
      "Epoch 17/30, Loss: 0.052191\n",
      "Epoch 18/30, Loss: 0.051891\n",
      "Epoch 19/30, Loss: 0.051595\n",
      "Epoch 20/30, Loss: 0.051309\n",
      "Epoch 21/30, Loss: 0.051051\n",
      "Epoch 22/30, Loss: 0.050820\n",
      "Epoch 23/30, Loss: 0.050586\n",
      "Epoch 24/30, Loss: 0.050384\n",
      "Epoch 25/30, Loss: 0.050204\n",
      "Epoch 26/30, Loss: 0.050050\n",
      "Epoch 27/30, Loss: 0.049911\n",
      "Epoch 28/30, Loss: 0.049804\n",
      "Epoch 29/30, Loss: 0.049733\n",
      "Epoch 30/30, Loss: 0.049682\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for states, actions in Data_loader:\n",
    "        \n",
    "        pred_actions = ACTOR_NETWORK(states)\n",
    "        \n",
    "        loss = loss_func(pred_actions, actions)\n",
    "        \n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(ACTOR_NETWORK.parameters(), max_norm = 0.5)\n",
    "        OPTIMIZER.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    SCHEDULER.step()\n",
    "        \n",
    "    avg_loss = running_loss / len(Data_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
